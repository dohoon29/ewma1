
from dataclasses import dataclass
from typing import Optional, List, Dict, Any, Tuple
import pandas as pd, numpy as np, json
import math

def _ensure_dt_index(s: pd.Series) -> pd.Series:
    """
    pandas Seriesì˜ ì¸ë±ìŠ¤ê°€ DatetimeIndexì¸ì§€ í™•ì¸í•˜ê³  ì •ë¦¬í•©ë‹ˆë‹¤.
    
    Args:
        s: ê²€ì‚¬í•  pandas Series
        
    Returns:
        ì¤‘ë³µ ì œê±° ë° ì •ë ¬ëœ pandas Series
        
    Raises:
        ValueError: ì¸ë±ìŠ¤ê°€ DatetimeIndexê°€ ì•„ë‹Œ ê²½ìš°
    """
    if not isinstance(s.index, pd.DatetimeIndex):
        raise ValueError("Series/DataFrame must use DatetimeIndex.")
    if s.index.has_duplicates:
        # ì¤‘ë³µëœ íƒ€ì„ìŠ¤íƒ¬í”„ ì œê±° (ì²« ë²ˆì§¸ ê°’ë§Œ ìœ ì§€)
        s = s[~s.index.duplicated(keep="first")]
    return s.sort_index()

def _mad_scaled(x: np.ndarray) -> float:
    """
    ì¤‘ì•™ê°’ ì ˆëŒ€ í¸ì°¨(MAD)ë¥¼ ê³„ì‚°í•˜ê³  ì •ê·œë¶„í¬ í‘œì¤€í¸ì°¨ì™€ ìœ ì‚¬í•˜ê²Œ ìŠ¤ì¼€ì¼ë§í•©ë‹ˆë‹¤.
    
    ì´ìƒì¹˜ì— ëœ ë¯¼ê°í•œ ë¶„ì‚° ì¶”ì •ì¹˜ë¡œ, ì •ê·œë¶„í¬ì—ì„œ MAD * 1.4826 â‰ˆ í‘œì¤€í¸ì°¨ì…ë‹ˆë‹¤.
    
    Args:
        x: ë¶„ì„í•  numpy ë°°ì—´
        
    Returns:
        ìŠ¤ì¼€ì¼ë§ëœ MAD ê°’ (í‘œì¤€í¸ì°¨ ì¶”ì •ì¹˜)
    """
    med = np.median(x)  # ì¤‘ì•™ê°’ ê³„ì‚°
    mad = np.median(np.abs(x - med))  # ì¤‘ì•™ê°’ìœ¼ë¡œë¶€í„°ì˜ ì ˆëŒ€ í¸ì°¨ì˜ ì¤‘ì•™ê°’
    return 1.4826 * mad  # ì •ê·œë¶„í¬ ê°€ì • í•˜ì— í‘œì¤€í¸ì°¨ì™€ ë™ë“±í•˜ê²Œ ìŠ¤ì¼€ì¼ë§

def _nearest_join(left: pd.DataFrame, right: pd.DataFrame, on: str, tol_s: float) -> pd.DataFrame:
    """
    ë‘ DataFrameì„ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ê°€ì¥ ê°€ê¹Œìš´ ê°’ìœ¼ë¡œ ì¡°ì¸í•©ë‹ˆë‹¤.
    
    ì£¼ë¡œ ì‹œê°„ ê°„ê²©ì´ ë‹¤ë¥¸ ì„¼ì„œ ë°ì´í„°ë¥¼ í†µí•©í•  ë•Œ ì‚¬ìš©ë©ë‹ˆë‹¤.
    ì˜ˆ: 2ì´ˆ ê°„ê²© ì „ë ¥ ë°ì´í„° + 10ë¶„ ê°„ê²© ë‚ ì”¨ ë°ì´í„°
    
    Args:
        left: ê¸°ì¤€ì´ ë˜ëŠ” DataFrame (ì‹œê°„ ì¸ë±ìŠ¤)
        right: ì¡°ì¸í•  DataFrame (ì‹œê°„ ì¸ë±ìŠ¤)
        on: ì¡°ì¸í•  ì»¬ëŸ¼ëª…
        tol_s: í—ˆìš© ì˜¤ì°¨ (ì´ˆ ë‹¨ìœ„)
        
    Returns:
        left DataFrameì— rightì˜ ë°ì´í„°ê°€ ì¡°ì¸ëœ ê²°ê³¼
    """
    tol = pd.to_timedelta(tol_s, unit="s")  # í—ˆìš© ì˜¤ì°¨ë¥¼ timedeltaë¡œ ë³€í™˜
    r = right[[on]].copy()
    r = r[~r.index.duplicated(keep="first")].sort_index()  # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
    # leftì˜ ê° ì‹œì ì— ëŒ€í•´ rightì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ ì‹œì ì˜ ê°’ì„ ì°¾ì•„ ë§¤ì¹­
    matched = r.reindex(left.index, method="nearest", tolerance=tol)
    out = left.copy()
    out[on] = matched[on].values  # ë§¤ì¹­ëœ ê°’ì„ leftì— ì¶”ê°€
    return out

@dataclass
class EWMABaseline:
    n: int
    sum: float
    sum_sqr: float

    @classmethod
    def from_json(cls, path: str) -> "EWMABaseline":
        with open(path, "r", encoding="utf-8") as f:
            d = json.load(f)
        return cls(n=int(d["n"]), sum=float(d["sum"]), sum_sqr=float(d["sum_sqr"]))

    def mean(self) -> float:
        """
        ëˆ„ì ëœ í†µê³„ë¡œë¶€í„° í‰ê· ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        Returns:
            ì „ë ¥ ë°ì´í„°ì˜ í‰ê· ê°’ (W)
        """
        return self.sum / max(1, self.n)  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€

    def std(self) -> float:
        """
        ëˆ„ì ëœ í†µê³„ë¡œë¶€í„° í‘œì¤€í¸ì°¨ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        ì˜¨ë¼ì¸ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ íš¨ìœ¨ì ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.
        ê³µì‹: Ïƒ = âˆš(E[XÂ²] - E[X]Â²)
        
        Returns:
            ì „ë ¥ ë°ì´í„°ì˜ í‘œì¤€í¸ì°¨ (W)
        """
        mu = self.mean()
        # ë¶„ì‚° = E[XÂ²] - E[X]Â² (ìŒìˆ˜ ë°©ì§€ë¥¼ ìœ„í•´ max ì‚¬ìš©)
        variance = max(0.0, self.sum_sqr / max(1, self.n) - mu*mu)
        return math.sqrt(variance)

@dataclass
class Config:
    ewma_alpha: float = 0.2
    ewma_k: float = 3.0
    ewma_sustain_sec: float = 10.0
    mains_voltage_V: float = 220.0
    current_limit_A: float = 30.0
    near_limit_ratio: float = 0.9
    near_limit_min_sec: float = 4.0
    spike_delta_A: float = 10.0
    spike_abs_A: float = 40.0
    spike_quiet_sec: float = 4.0
    summer_months: tuple = (6,7,8)
    winter_months: tuple = (12,1,2)
    summer_indoor_over_outdoor_warn: float = 1.0
    summer_indoor_over_outdoor_alert: float = 3.0
    winter_indoor_above_outdoor_min_warn: float = 5.0
    winter_indoor_above_outdoor_min_alert: float = 3.0
    use_lux_gate: bool = True
    occupancy_lux_threshold: float = 20.0

@dataclass
class Event:
    type: str
    start: pd.Timestamp
    end: pd.Timestamp
    severity: str
    info: Dict[str, Any]

class StreamingDetector:
    def __init__(self, baseline: EWMABaseline, cfg: Optional[Config] = None, sample_period_s: float = 2.0):
        self.baseline = baseline
        self.cfg = cfg or Config()
        self.dt = float(sample_period_s)
        self._ewma = 0.0
        self._ewma_breaching = False
        self._ewma_start = None
        self._ewma_peak = 0.0
        self._over_start = None
        self._over_active = False
        self._last_I = None
        self._last_ts = None
        self._n = baseline.n
        self._sum = baseline.sum
        self._sum_sqr = baseline.sum_sqr

    def _lux_ok(self, lux: Optional[float]) -> bool:
        if not self.cfg.use_lux_gate:
            return True
        return (lux is not None) and (lux >= self.cfg.occupancy_lux_threshold)

    def _update_stats(self, value_w: float):
        """
        ìƒˆë¡œìš´ ì „ë ¥ ê°’ìœ¼ë¡œ ëˆ„ì  í†µê³„ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
        
        ì˜¨ë¼ì¸ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ í†µê³„ ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        Args:
            value_w: ìƒˆë¡œìš´ ì „ë ¥ ê°’ (W)
        """
        self._n += 1  # ë°ì´í„° í¬ì¸íŠ¸ ê°œìˆ˜ ì¦ê°€
        self._sum += value_w  # í•©ê³„ ì—…ë°ì´íŠ¸
        self._sum_sqr += value_w * value_w  # ì œê³±í•© ì—…ë°ì´íŠ¸

    def _stats(self) -> Tuple[float,float]:
        """
        í˜„ì¬ ëˆ„ì  í†µê³„ë¡œë¶€í„° í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        Returns:
            (í‰ê· , í‘œì¤€í¸ì°¨) íŠœí”Œ (ë‹¨ìœ„: W)
        """
        mu = self._sum / max(1, self._n)  # í‰ê·  ê³„ì‚°
        # ë¶„ì‚° ê³„ì‚° (ìŒìˆ˜ ë°©ì§€)
        var = max(0.0, self._sum_sqr / max(1, self._n) - mu*mu)
        return mu, math.sqrt(var)  # (í‰ê· , í‘œì¤€í¸ì°¨) ë°˜í™˜

    def update(self, ts: pd.Timestamp, power_W: float,
               room_temp_C: Optional[float] = None,
               room_rh_pct: Optional[float] = None,
               lux: Optional[float] = None,
               outdoor_temp_C: Optional[float] = None) -> List[Event]:
        out: List[Event] = []

        # EWMA on power_W
        self._update_stats(power_W)
        mu, sd = self._stats()
        alpha = self.cfg.ewma_alpha
        self._ewma = alpha * power_W + (1 - alpha) * self._ewma
        z = 0.0 if sd == 0.0 else (power_W - self._ewma) / sd
        above = abs(z) > self.cfg.ewma_k

        if above and not self._ewma_breaching:
            self._ewma_breaching = True
            self._ewma_start = ts
            self._ewma_peak = abs(z)
        elif above and self._ewma_breaching:
            self._ewma_peak = max(self._ewma_peak, abs(z))
        elif (not above) and self._ewma_breaching:
            duration = (ts - self._ewma_start).total_seconds()
            if duration >= self.cfg.ewma_sustain_sec:
                out.append(Event(
                    type="power_ewma_anomaly",
                    start=self._ewma_start, end=ts, severity="alert",
                    info={"z_peak": float(self._ewma_peak), "mu_W": float(mu), "sd_W": float(sd)}
                ))
            self._ewma_breaching = False
            self._ewma_start = None
            self._ewma_peak = 0.0

        # Electrical in Amps (power / V)
        V = self.cfg.mains_voltage_V
        I = power_W / max(1e-9, V)

        warn_level = self.cfg.near_limit_ratio * self.cfg.current_limit_A
        if I >= warn_level:
            if not self._over_active:
                self._over_active = True
                self._over_start = ts
            else:
                duration = (ts - self._over_start).total_seconds()
                if duration >= self.cfg.near_limit_min_sec:
                    sev = "alert" if I >= self.cfg.current_limit_A else "warn"
                    out.append(Event(
                        type="overcurrent_near_limit",
                        start=self._over_start, end=ts, severity=sev,
                        info={"I_A": float(I), "limit_A": float(self.cfg.current_limit_A),
                              "ratio": float(I / self.cfg.current_limit_A)}
                    ))
                    self._over_start = ts
        else:
            self._over_active = False
            self._over_start = None

        if self._last_I is not None and self._last_ts is not None:
            dI = I - self._last_I
            if (abs(dI) >= self.cfg.spike_delta_A) or (I >= self.cfg.spike_abs_A):
                out.append(Event(
                    type="short_spike_suspect",
                    start=self._last_ts, end=ts, severity="alert",
                    info={"delta_A": float(dI), "I_A": float(I)}
                ))
        self._last_I = I
        self._last_ts = ts

        # Thermal vs outdoor
        if (room_temp_C is not None) and (outdoor_temp_C is not None) and self._lux_ok(lux):
            m = ts.month
            if m in self.cfg.summer_months:
                diff = room_temp_C - outdoor_temp_C
                if diff >= self.cfg.summer_indoor_over_outdoor_alert:
                    out.append(Event("thermal_summer_room_hot_vs_outdoor", ts, ts, "alert",
                                     {"room_C": float(room_temp_C), "outdoor_C": float(outdoor_temp_C), "delta_C": float(diff)}))
                elif diff >= self.cfg.summer_indoor_over_outdoor_warn:
                    out.append(Event("thermal_summer_room_hot_vs_outdoor", ts, ts, "warn",
                                     {"room_C": float(room_temp_C), "outdoor_C": float(outdoor_temp_C), "delta_C": float(diff)}))
            if m in self.cfg.winter_months:
                diff = room_temp_C - outdoor_temp_C
                if diff <= self.cfg.winter_indoor_above_outdoor_min_alert:
                    out.append(Event("thermal_winter_room_too_cold_vs_outdoor", ts, ts, "alert",
                                     {"room_C": float(room_temp_C), "outdoor_C": float(outdoor_temp_C), "delta_C": float(diff)}))
                elif diff <= self.cfg.winter_indoor_above_outdoor_min_warn:
                    out.append(Event("thermal_winter_room_too_cold_vs_outdoor", ts, ts, "warn",
                                     {"room_C": float(room_temp_C), "outdoor_C": float(outdoor_temp_C), "delta_C": float(diff)}))
        return out

# ì¤‘ë³µëœ í´ë˜ìŠ¤ ì •ì˜ ì œê±°ë¨ - ìœ„ì— ì´ë¯¸ ì •ì˜ë˜ì–´ ìˆìŒ

def run_batch(
    input_csv: str,
    baseline_json: str,
    weather_csv: Optional[str] = None,
    tz: Optional[str] = None,
    cfg: Optional[Config] = None,
    sample_period_s: float = 2.0,
    out_csv: Optional[str] = None,
    weather_col_candidates: tuple = ("outside_temp_C","outdoor_temp_C","temp_out_C"),
) -> pd.DataFrame:
    """
    ë°°ì¹˜ ëª¨ë“œë¡œ ì´ìƒ íƒì§€ë¥¼ ì‹¤í–‰í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜.
    CSV íŒŒì¼ë¡œë¶€í„° ë°ì´í„°ë¥¼ ì½ì–´ì™€ StreamingDetectorë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ìƒ ì§•í›„ë¥¼ íƒì§€í•©ë‹ˆë‹¤.

    input_csv: ì „ë ¥ ë° í™˜ê²½ ì„¼ì„œ ë°ì´í„°ê°€ í¬í•¨ëœ ì…ë ¥ CSV íŒŒì¼ ê²½ë¡œ.
    baseline_json: EWMA ë² ì´ìŠ¤ë¼ì¸ í†µê³„ê°€ ì €ì¥ëœ JSON íŒŒì¼ ê²½ë¡œ.
    weather_csv: (ì„ íƒ ì‚¬í•­) ì™¸ë¶€ ì˜¨ë„ ë°ì´í„°ê°€ í¬í•¨ëœ CSV íŒŒì¼ ê²½ë¡œ.
    tz: (ì„ íƒ ì‚¬í•­) íƒ€ì„ìŠ¤íƒ¬í”„ì— ì ìš©í•  ì‹œê°„ëŒ€ (ì˜ˆ: "Asia/Seoul").
    cfg: (ì„ íƒ ì‚¬í•­) íƒì§€ ì„¤ì •ì„ í¬í•¨í•˜ëŠ” Config ê°ì²´.
    sample_period_s: ë°ì´í„° ìƒ˜í”Œë§ ì£¼ê¸° (ì´ˆ).
    out_csv: (ì„ íƒ ì‚¬í•­) íƒì§€ëœ ì´ë²¤íŠ¸ë¥¼ ì €ì¥í•  ì¶œë ¥ CSV íŒŒì¼ ê²½ë¡œ.
    weather_col_candidates: weather_csvì—ì„œ ì™¸ë¶€ ì˜¨ë„ ì»¬ëŸ¼ì„ ì°¾ì„ ë•Œ ì‚¬ìš©í•  í›„ë³´ ì»¬ëŸ¼ëª… íŠœí”Œ.
    """
    cfg = cfg or Config() # ì„¤ì • ê°ì²´ ì´ˆê¸°í™”

    # 1. ì…ë ¥ CSV íŒŒì¼ ë¡œë“œ ë° ì „ì²˜ë¦¬
    print(f"ğŸ“ ì…ë ¥ íŒŒì¼ ë¡œë“œ ì¤‘: {input_csv}")
    df = pd.read_csv(input_csv)
    print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ í–‰, {len(df.columns)}ê°œ ì»¬ëŸ¼")
    
    # íƒ€ì„ìŠ¤íƒ¬í”„ ì»¬ëŸ¼ ì°¾ê¸° ë° DatetimeIndexë¡œ ì„¤ì •
    # ë‹¤ì–‘í•œ íƒ€ì„ìŠ¤íƒ¬í”„ ì»¬ëŸ¼ëª…ì„ ì§€ì› (timestamp, time, ts, datetime)
    ts_col = [c for c in df.columns if str(c).lower() in ("timestamp","time","ts","datetime")]
    if not ts_col:
        raise ValueError("input_csv must contain a 'timestamp' column")
    ts_col = ts_col[0]
    print(f"ğŸ• íƒ€ì„ìŠ¤íƒ¬í”„ ì»¬ëŸ¼ ë°œê²¬: '{ts_col}'")
    
    df[ts_col] = pd.to_datetime(df[ts_col]) # datetime ê°ì²´ë¡œ ë³€í™˜
    if tz:
        # ì‹œê°„ëŒ€ ì„¤ì • (DST ë° ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì‹œê°„ ì²˜ë¦¬ í¬í•¨)
        df[ts_col] = df[ts_col].dt.tz_localize(tz, ambiguous='NaT', nonexistent='shift_forward')
        print(f"ğŸŒ ì‹œê°„ëŒ€ ì„¤ì •: {tz}")
    
    df = df.set_index(ts_col).sort_index() # ì¸ë±ìŠ¤ë¥¼ íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ì„¤ì •í•˜ê³  ì‹œê°„ìˆœ ì •ë ¬
    print(f"ğŸ“Š ë°ì´í„° ê¸°ê°„: {df.index.min()} ~ {df.index.max()}")

    # ì „ë ¥ ì»¬ëŸ¼ ì°¾ê¸° (ë‹¤ì–‘í•œ ëª…ëª… ê·œì¹™ ì§€ì›)
    p_cols = [c for c in df.columns if str(c).lower() in ("power_w","power","watts","w")]
    if not p_cols:
        raise ValueError("input_csv must contain a power column (power_W/power/watts/w)")
    p_col = p_cols[0]
    print(f"âš¡ ì „ë ¥ ì»¬ëŸ¼ ë°œê²¬: '{p_col}' (ë²”ìœ„: {df[p_col].min():.1f}W ~ {df[p_col].max():.1f}W)")

    # ì„ íƒì  í™˜ê²½ ì„¼ì„œ ì»¬ëŸ¼ëª… í‘œì¤€í™”
    # ë‹¤ì–‘í•œ ì„¼ì„œ ë°ì´í„° í¬ë§·ì„ í†µì¼ëœ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë³€í™˜
    col_map = {}
    sensor_mapping = [
        ("temp_c", "room_temp_C", "ì‹¤ë‚´ì˜¨ë„"),
        ("room_temp_c", "room_temp_C", "ì‹¤ë‚´ì˜¨ë„"), 
        ("rh", "rh_pct", "ìƒëŒ€ìŠµë„"),
        ("humidity", "rh_pct", "ìƒëŒ€ìŠµë„"),
        ("lux", "lux", "ì¡°ë„")
    ]
    
    found_sensors = []
    for cand, name, desc in sensor_mapping:
        for c in df.columns:
            if str(c).lower() == cand:
                col_map[c] = name
                found_sensors.append(f"{desc}({c})")
    
    df = df.rename(columns=col_map)
    if found_sensors:
        print(f"ğŸŒ¡ï¸  í™˜ê²½ ì„¼ì„œ ë°œê²¬: {', '.join(found_sensors)}")
    else:
        print("âš ï¸  í™˜ê²½ ì„¼ì„œ ë°ì´í„° ì—†ìŒ (ì „ë ¥ ê¸°ë°˜ íƒì§€ë§Œ ìˆ˜í–‰)")

    # 2. ì™¸ë¶€ ë‚ ì”¨ CSV íŒŒì¼ ë¡œë“œ ë° ì¡°ì¸ (ì„ íƒ ì‚¬í•­)
    # ì˜¨ë„ ê¸°ë°˜ ì´ìƒ íƒì§€ë¥¼ ìœ„í•œ ì‹¤ì™¸ ì˜¨ë„ ë°ì´í„° í†µí•©
    if weather_csv:
        print(f"ğŸŒ¤ï¸  ì™¸ë¶€ ë‚ ì”¨ ë°ì´í„° ë¡œë“œ ì¤‘: {weather_csv}")
        w = pd.read_csv(weather_csv)
        
        # ë‚ ì”¨ ë°ì´í„°ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ ì»¬ëŸ¼ ì°¾ê¸° ë° DatetimeIndexë¡œ ì„¤ì •
        w_ts_col = [c for c in w.columns if str(c).lower() in ("timestamp","time","ts","datetime")]
        if not w_ts_col:
            raise ValueError("weather_csv must have a timestamp column")
        w_ts_col = w_ts_col[0]
        w[w_ts_col] = pd.to_datetime(w[w_ts_col])
        if tz:
            w[w_ts_col] = w[w_ts_col].dt.tz_localize(tz, ambiguous='NaT', nonexistent='shift_forward')
        w = w.set_index(w_ts_col).sort_index()
        
        # ì™¸ë¶€ ì˜¨ë„ ì»¬ëŸ¼ ì°¾ê¸° (ë‹¤ì–‘í•œ ì»¬ëŸ¼ëª… ì§€ì›)
        w_temp_col = None
        for cand in weather_col_candidates:
            for c in w.columns:
                if str(c).lower() == cand.lower():
                    w_temp_col = c
                    break
            if w_temp_col:
                break
        if w_temp_col is None:
            raise ValueError(f"weather_csv must contain one of {weather_col_candidates}")
        
        # ë©”ì¸ ë°ì´í„°í”„ë ˆì„ì— ì™¸ë¶€ ì˜¨ë„ ë°ì´í„° ì‹œê°„ ê¸°ì¤€ ì¡°ì¸
        # 600ì´ˆ(10ë¶„) í—ˆìš© ì˜¤ì°¨ë¡œ ê°€ì¥ ê°€ê¹Œìš´ ì‹œê°„ì˜ ë‚ ì”¨ ë°ì´í„°ë¥¼ ë§¤ì¹­
        before_join = len(df)
        df = _nearest_join(df, w[[w_temp_col]].rename(columns={w_temp_col: "outside_temp_C"}),
                           on="outside_temp_C", tol_s=600)
        matched_count = df['outside_temp_C'].notna().sum()
        print(f"ğŸ”— ë‚ ì”¨ ë°ì´í„° ì¡°ì¸ ì™„ë£Œ: {matched_count}/{before_join}ê°œ ì‹œì  ë§¤ì¹­")
    else:
        print("ğŸŒ¡ï¸  ì™¸ë¶€ ë‚ ì”¨ ë°ì´í„° ì—†ìŒ (ì˜¨ë„ ê¸°ë°˜ íƒì§€ ë¹„í™œì„±í™”)")

    # 3. ì´ìƒ íƒì§€ ì—”ì§„ ì´ˆê¸°í™”
    print(f"ğŸ§  ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ ë¡œë“œ ì¤‘: {baseline_json}")
    base = EWMABaseline.from_json(baseline_json) # ì‚¬ì „ í•™ìŠµëœ í†µê³„ ë² ì´ìŠ¤ë¼ì¸ ë¡œë“œ
    print(f"ğŸ“ˆ ë² ì´ìŠ¤ë¼ì¸ í†µê³„: í‰ê· ={base.mean():.1f}W, í‘œì¤€í¸ì°¨={base.std():.1f}W (í•™ìŠµ ë°ì´í„°: {base.n:,}ê°œ)")
    
    # ìŠ¤íŠ¸ë¦¬ë° íƒì§€ê¸° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    det = StreamingDetector(base, cfg=cfg, sample_period_s=sample_period_s)
    print(f"ğŸ” íƒì§€ê¸° ì´ˆê¸°í™” ì™„ë£Œ (ìƒ˜í”Œë§ ì£¼ê¸°: {sample_period_s}ì´ˆ)")
    print(f"âš™ï¸  íƒì§€ ì„¤ì •: EWMA_k={cfg.ewma_k}, ì „ë¥˜í•œê³„={cfg.current_limit_A}A, ìŠ¤íŒŒì´í¬ì„ê³„={cfg.spike_delta_A}A")

    # 4. ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì´ìƒ íƒì§€ ìˆ˜í–‰
    print(f"ğŸš€ ì´ìƒ íƒì§€ ì‹œì‘... (ì²˜ë¦¬ ëŒ€ìƒ: {len(df):,}ê°œ ë°ì´í„° í¬ì¸íŠ¸)")
    
    rows = []  # íƒì§€ëœ ì´ë²¤íŠ¸ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    processed_count = 0
    
    # ë°ì´í„°í”„ë ˆì„ì˜ ê° ì‹œì ì„ ìˆœíšŒí•˜ë©° ì‹¤ì‹œê°„ íƒì§€ ì‹œë®¬ë ˆì´ì…˜
    for ts, row in df.iterrows():
        # StreamingDetectorì— ìƒˆë¡œìš´ ë°ì´í„° í¬ì¸íŠ¸ ì…ë ¥
        evs = det.update(
            ts = ts,  # í˜„ì¬ íƒ€ì„ìŠ¤íƒ¬í”„
            power_W = float(row[p_col]),  # ì „ë ¥ ë°ì´í„° (í•„ìˆ˜)
            # ì„ íƒì  í™˜ê²½ ì„¼ì„œ ë°ì´í„° (ì—†ê±°ë‚˜ NaNì´ë©´ Noneìœ¼ë¡œ ì „ë‹¬)
            room_temp_C = float(row["room_temp_C"]) if "room_temp_C" in row and not pd.isna(row["room_temp_C"]) else None,
            room_rh_pct = float(row["rh_pct"]) if "rh_pct" in row and not pd.isna(row["rh_pct"]) else None,
            lux = float(row["lux"]) if "lux" in row and not pd.isna(row["lux"]) else None,
            outdoor_temp_C = float(row["outside_temp_C"]) if "outside_temp_C" in row and not pd.isna(row["outside_temp_C"]) else None,
        )
        
        # íƒì§€ëœ ì´ë²¤íŠ¸ë“¤ì„ ê²°ê³¼ ëª©ë¡ì— ì¶”ê°€
        for e in evs:
            rows.append(dict(
                type=e.type,  # ì´ë²¤íŠ¸ ìœ í˜•
                start=e.start,  # ì‹œì‘ ì‹œê°„
                end=e.end,  # ì¢…ë£Œ ì‹œê°„
                severity=e.severity,  # ì‹¬ê°ë„ (warn/alert)
                info_json=json.dumps(e.info, ensure_ascii=False)  # ìƒì„¸ ì •ë³´ (JSON)
            ))
            print(f"ğŸš¨ ì´ìƒ íƒì§€: {e.type} ({e.severity}) at {e.start}")
        
        processed_count += 1
        # ì§„í–‰ ìƒí™© ì¶œë ¥ (ë§¤ 10000ê°œë§ˆë‹¤)
        if processed_count % 10000 == 0:
            print(f"ğŸ“Š ì§„í–‰ë¥ : {processed_count:,}/{len(df):,} ({100*processed_count/len(df):.1f}%)")
    
    # íƒì§€ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
    out_df = pd.DataFrame(rows)
    print(f"âœ… íƒì§€ ì™„ë£Œ! ì´ {len(out_df)}ê°œì˜ ì´ìƒ ì´ë²¤íŠ¸ ë°œê²¬")

    # 5. ê²°ê³¼ ì €ì¥ ë° ìš”ì•½
    if out_csv:
        out_df.to_csv(out_csv, index=False)
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {out_csv}")
    
    # íƒì§€ ê²°ê³¼ ìš”ì•½ ì¶œë ¥
    if not out_df.empty:
        print("\nğŸ“‹ íƒì§€ ê²°ê³¼ ìš”ì•½:")
        summary = out_df.groupby(['type', 'severity']).size().reset_index(name='count')
        for _, row in summary.iterrows():
            print(f"   â€¢ {row['type']} ({row['severity']}): {row['count']}ê±´")
    else:
        print("âœ¨ ì´ìƒ ì§•í›„ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    return out_df  # íƒì§€ëœ ì´ë²¤íŠ¸ DataFrame ë°˜í™˜

    # í•¨ìˆ˜ ì¢…ë£Œ - ìœ„ì—ì„œ ëª¨ë“  ë¡œì§ì´ ì™„ë£Œë¨
